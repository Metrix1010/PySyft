{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# Partie 2: Introduction à l'apprentissage fédéré\n",
    "\n",
    "Dans la dernière section, nous avons découvert les PointerTensors, qui créent l'infrastructure sous-jacente dont nous avons besoin pour préserver la confidentialité du Deep Learning. Dans cette section, nous allons voir comment utiliser ces outils de base pour implémenter notre premier algorithme d'apprentissage en profondeur préservant la confidentialité, Federated Learning.\n",
    "\n",
    "Auteurs:\n",
    "- Andrew Trask - Twitter: [@iamtrask] (https://twitter.com/iamtrask)\n",
    "\n",
    "### Qu'est-ce que l'apprentissage fédéré?\n",
    "\n",
    "C'est un moyen simple et puissant de former des modèles Deep Learning. Si vous pensez aux données de formation, c'est toujours le résultat d'une sorte de processus de collecte. Les gens (via des appareils) génèrent des données en enregistrant des événements dans le monde réel. Normalement, ces données sont agrégées en un seul emplacement central afin que vous puissiez former un modèle d'apprentissage automatique. L'apprentissage fédéré fait tourner la tête!\n",
    "\n",
    "Au lieu d'apporter des données de formation au modèle (un serveur central), vous apportez le modèle aux données de formation (où qu'il se trouve).\n",
    "\n",
    "L'idée est que cela permet à celui qui crée les données de posséder la seule copie permanente, et ainsi de garder le contrôle sur qui y a accès. Assez cool, hein?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# Section 2.1 - Un exemple d'apprentissage fédéré de jouets\n",
    "\n",
    "Commençons par former un modèle de jouet de manière centralisée. Il s'agit d'un simple que les modèles obtiennent. Nous devons d'abord:\n",
    "\n",
    "- un jeu de données jouet\n",
    "- un modèle\n",
    "- une logique de formation de base pour la formation d'un modèle pour ajuster les données.\n",
    "\n",
    "Remarque: Si cette API ne vous est pas familière, rendez-vous sur [fast.ai] (http://fast.ai) et suivez leur cours avant de continuer dans ce didacticiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# un jeu de données jouet\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# un modèle de jouet\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "def train():\n",
    "    # logique de formation\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(20):\n",
    "\n",
    "        # 1) effacer les dégradés précédents (s'ils existent)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # 2) faire une prédiction\n",
    "        pred = model(data)\n",
    "\n",
    "        # 3) calculer combien nous avons manqué\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        # 4) déterminer quels poids nous ont fait manquer\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) changer ces poids\n",
    "        opt.step()\n",
    "\n",
    "        # 6) imprimer nos progrès\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "Et voila! Nous avons formé un modèle de base de manière conventionnelle. Toutes nos données sont agrégées dans notre machine locale et nous pouvons les utiliser pour effectuer des mises à jour de notre modèle. L'apprentissage fédéré, cependant, ne fonctionne pas de cette façon. Modifions donc cet exemple pour le faire de la manière de l'apprentissage fédéré!\n",
    "\n",
    "Alors, de quoi avons-nous besoin:\n",
    "\n",
    "- créer un couple de travailleurs\n",
    "- obtenir des conseils sur les données de formation sur chaque travailleur\n",
    "- logique de formation mise à jour pour faire un apprentissage fédéré\n",
    "\n",
    "    Nouvelles étapes de formation:\n",
    "    - envoyer le modèle au bon travailleur\n",
    "    - s'entraîner sur les données qui s'y trouvent\n",
    "    - récupérer le modèle et répéter avec le prochain travailleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un couple de travailleurs\n",
    "\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un jeu de données jouet\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# obtenir des conseils sur les données de formation de chaque travailleur en envoyant\n",
    "# des données de formation à bob et alice\n",
    "data_bob = data[0:2]\n",
    "target_bob = target[0:2]\n",
    "\n",
    "data_alice = data[2:]\n",
    "target_alice = target[2:]\n",
    "\n",
    "# Initialiser un modèle de jouet\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "data_bob = data_bob.send(bob)\n",
    "data_alice = data_alice.send(alice)\n",
    "target_bob = target_bob.send(bob)\n",
    "target_alice = target_alice.send(alice)\n",
    "\n",
    "# organiser les pointeurs dans une liste\n",
    "datasets = [(data_bob,target_bob),(data_alice,target_alice)]\n",
    "\n",
    "opt = optim.SGD(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # logique de formation\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(10):\n",
    "        \n",
    "        # NOUVEAU) parcourez l'ensemble de données de chaque travailleur\n",
    "        for data,target in datasets:\n",
    "            \n",
    "            # NOUVEAU) envoyer le modèle au bon travailleur\n",
    "            model.send(data.location)\n",
    "\n",
    "            # 1) effacer les dégradés précédents (s'ils existent)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # 2) faire une prédiction\n",
    "            pred = model(data)\n",
    "\n",
    "            # 3) calculer combien nous avons manqué\n",
    "            loss = ((pred - target)**2).sum()\n",
    "\n",
    "            # 4) déterminer quels poids nous ont fait manquer\n",
    "            loss.backward()\n",
    "\n",
    "            # 5) changer ces poids\n",
    "            opt.step()\n",
    "            \n",
    "            # NOUVEAU) obtenir le modèle (avec des dégradés)\n",
    "            model.get()\n",
    "\n",
    "            # 6) imprimer nos progrès\n",
    "            print(loss.get()) # NOUVEAU) légère modification ... besoin d'appeler .get () en cas de loss\\\n",
    "    \n",
    "# moyenne fédérée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "## Bien joué!\n",
    "\n",
    "Et voilà! Nous formons maintenant un modèle d'apprentissage en profondeur très simple en utilisant l'apprentissage fédéré! Nous envoyons le modèle à chaque travailleur, générons un nouveau gradient, puis le rapportons à notre serveur local où nous mettons à jour notre modèle global. Jamais dans ce processus, nous ne voyons ou ne demandons l'accès aux données de formation sous-jacentes! Nous préservons l'intimité de Bob et Alice !!!\n",
    "\n",
    "## Lacunes de cet exemple\n",
    "\n",
    "Ainsi, bien que cet exemple soit une belle introduction à l'apprentissage fédéré, il présente encore quelques lacunes majeures. Plus particulièrement, lorsque nous appelons `model.get ()` et recevons le modèle mis à jour de Bob ou Alice, nous pouvons en fait en apprendre beaucoup sur les données d'entraînement de Bob et Alice en regardant leurs gradients. Dans certains cas, nous pouvons parfaitement restaurer leurs données d'entraînement!\n",
    "\n",
    "Alors, que faire? Eh bien, la première stratégie que les gens utilisent consiste à **faire la moyenne du gradient sur plusieurs individus avant de le télécharger sur le serveur central**. Cette stratégie, cependant, nécessitera une utilisation plus sophistiquée des objets PointerTensor. Donc, dans la section suivante, nous allons prendre un certain temps pour en savoir plus sur les fonctionnalités de pointeur plus avancées, puis nous mettrons à niveau cet exemple d'apprentissage fédéré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "fr"
   },
   "source": [
    "# Toutes nos félicitations!!! - Il est temps de rejoindre la communauté!\n",
    "\n",
    "Félicitations pour avoir terminé ce didacticiel pour ordinateur portable! Si cela vous a plu et que vous souhaitez rejoindre le mouvement vers la préservation de la vie privée, la propriété décentralisée de l'IA et la chaîne d'approvisionnement de l'IA (données), vous pouvez le faire de la manière suivante!\n",
    "\n",
    "### Star PySyft sur GitHub\n",
    "\n",
    "La façon la plus simple d'aider notre communauté est de mettre en vedette les Repos! Cela permet de mieux faire connaître les outils sympas que nous construisons.\n",
    "\n",
    "- [Star PySyft] (https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Rejoignez notre Slack!\n",
    "\n",
    "La meilleure façon de vous tenir au courant des dernières avancées est de rejoindre notre communauté! Vous pouvez le faire en remplissant le formulaire à [http://slack.openmined.org] (http://slack.openmined.org)\n",
    "\n",
    "### Rejoignez un projet de code!\n",
    "\n",
    "La meilleure façon de contribuer à notre communauté est de devenir un contributeur de code! À tout moment, vous pouvez accéder à la page Problèmes de PySyft GitHub et filtrer pour \"Projets\". Cela vous montrera tous les billets de haut niveau donnant un aperçu des projets que vous pouvez rejoindre! Si vous ne souhaitez pas rejoindre un projet, mais que vous souhaitez faire un peu de codage, vous pouvez également rechercher d'autres mini-projets \"uniques\" en recherchant les problèmes GitHub marqués \"bon premier problème\".\n",
    "\n",
    "- [Projets PySyft] (https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Billets Good First Issue] (https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Faire un don\n",
    "\n",
    "Si vous n'avez pas le temps de contribuer à notre base de code, mais souhaitez tout de même apporter votre soutien, vous pouvez également devenir Backer sur notre Open Collective. Tous les dons vont à notre hébergement Web et à d'autres dépenses communautaires telles que les hackathons et les rencontres!\n",
    "\n",
    "[Open Collective Page d'OpenMined] (https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
